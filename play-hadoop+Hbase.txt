https://powcoder.com
代写代考加微信 powcoder
Assignment Project Exam Help
Add WeChat powcoder
https://powcoder.com
代写代考加微信 powcoder
Assignment Project Exam Help
Add WeChat powcoder

hadoop
hbase
----------------------------------------------------------------
Hadoop is now in Version 2 (as of 2016)
Linux
Java
Download   http://hadoop.apache.org/releases.html 
                         
Installation: https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html 
3 possible modes:
•	Local (Standalone) Mode
•	Pseudo-Distributed Mode
•	Fully-Distributed Mode

Run:
Start the server: 
start-dfs.sh, start-yarn.sh
Check the server status, 
“jps” sees 5 servers on the main node. 
“hdfs dfsadmin –report” displays the details
Write program
	~/Desktop/wordcount/WordCount.java
	~/Desktop/wordcount/input   to contain file01 and file02
Compile
export HADOOP_CLASSPATH=${JAVA_HOME}/lib/tools.jar
export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar
export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
hadoop com.sun.tools.javac.Main WordCount.java
jar cf wc.jar WordCount*.class
Upload data and program to Hadoop: 
Assume in local OS   ~/Desktop;    jrytest is the user’s home on Hadoop hdfs
hadoop fs -mkdir jrytest      # under hdfs root
hadoop fs -put –p ./wordcount  jrytest 
                  (local-path) (hdfs-path)
	hadoop fs -cat jrytest/wordcount/input/file01
Run the program:  in local OS ~/Desktop/workcount
hadoop jar ./wc.jar WordCount jrytest/wordcount/input dir1/wordcount/output
             NOTE: jrytest/wordcount/output must not be existing. 
See the results 
hadoop fs -cat jrytest/wordcount/output/part-r-00000

Stop servers 
stop-yarn.sh
stop-dfs.sh

------------------------------------------

Hbase and its installation 

http://www.tutorialspoint.com/hbase/hbase_read_data.htm

------- installation
download hbase and unzip to /usr/local

add the following to /usr/local/hbase-x.y.z/conf/hbase-env.sh
export JAVA_HOME=/usr/local/jdk1.8.0_73

edit ~/.bashrc to add    (.bash_profile better)
export HBASE_HOME=/usr/local/hbase-x.y.z
export PATH=$PATH:$HBASE_HOME/bin
source ~/.bashrc

configure settings
edit $HBASE_HOME/conf/hbase-site.xml to have 
<configuration>
    <property>
        <name>hbase.cluster.distributed</name>
        <value>true</value>
    </property>
    <property>
        <name>hbase:rootdir</name>
        <value>hdfs://localhost:8030/hbase</value>
    </property>
</configuration>

start-hbase.sh
this will starting zookeeper, master, regionserver.

jps shows:
2445 NameNode           #
2739 SecondaryNameNode  #
2953 ResourceManager    #
3085 NodeManager        #
2571 DataNode           #
6403 HMaster        *
6532 HRegionServer  *
6336 HQuorumPeer    *

hadoop fs -ls /hbase
  should get no error. 

hbase shell
    status - Provides the status of HBase, for example, the number of servers.
    version - Provides the version of HBase being used.
    table_help - Provides help for table-reference commands.
    whoami - Provides information about the user.
    
    *** Data Definition Language
    create - Creates a table.
    list - Lists all the tables in HBase.
    disable - Disables a table.
    is_disabled - Verifies whether a table is disabled.
    enable - Enables a table.
    is_enabled - Verifies whether a table is enabled.
    describe - Provides the description of a table.
    alter - Alters a table.
    exists - Verifies whether a table exists.
    drop - Drops a table from HBase.
    drop_all - Drops the tables matching the 'regex' given in the command.

    Java Admin API - Prior to all the above commands, Java provides an Admin API to achieve DDL functionalities through programming. Under org.apache.hadoop.hbase.client package, HBaseAdmin and HTableDescriptor are the two important classes in this package that provide DDL functionalities.

    *** Data Manipulation Language
    put - Puts a cell value at a specified column in a specified row in a particular table.
    get - Fetches the contents of row or a cell.
    delete - Deletes a cell value in a table.
    deleteall - Deletes all the cells in a given row.
    scan - Scans and returns the table data.
    count - Counts and returns the number of rows in a table.
    truncate - Disables, drops, and recreates a specified table.

    Java client API - Prior to all the above commands, Java provides a client API to achieve DML functionalities, CRUD (Create Retrieve Update Delete) operations and more through programming, under org.apache.hadoop.hbase.client package. HTable Put and Get are the important classes in this package.

https://learnhbase.wordpress.com/2013/03/02/hbase-shell-commands/

-------- tutorial

Creating a Table using HBase Shell

// create '<table name>','<column family>'[,'<column family>'] 

Example
Given below is a schema of a table named emp. 
It has two column families: “personal data” and “professional data”.

Row key	       personal data      professional data

You can create this table in HBase shell as shown below.
hbase(main):002:0> create 'emp', 'personaldata', 'professionaldata'
hbase(main):002:0> list
    TABLE 
    emp
    1 row(s) in 0.0340 seconds

describe "emp"

           personal data     professional data
recordNo   Name   City       Designation  Salary
1          John   Adel       manager      50
2          Rob    Mel        engineer     60
3          Andy   Syd        officer      35

// put 'tableName','rowKey','colFamily:attr','value'
put 'emp','1','personal data:name','raju'
put 'emp','1','personal data:city','hyderabad'
put 'emp','1','professional data:designation','manager'
put 'emp','1','professional data:salary','50'    
put 'emp','2','personal data:name','rob'
put 'emp','2','personal data:city','mel'
put 'emp','2','professional data:designation','engineer'
put 'emp','2','professional data:salary','60'    
put 'emp','3','personal data:name','andy'
put 'emp','3','personal data:city','syd'
put 'emp','3','professional data:designation','officer'
put 'emp','3','professional data:salary','35'    

get 'tableName','rowkey'[,colFamily:attr]    ## names may contain spaces, so quotes are needed. 
get 'emp','1'
or
get 'emp','1','personal data:city'    ## be careful of spaces
    COLUMN                          CELL
     personal data:city             timestamp=1456054153540, value=hyderabad
     personal data:name             timestamp=1456054153490, value=raju
     professional data:designation  timestamp=1456054153579, value=manager
     professional data:salary       timestamp=1456055091097, value=55
 
update a value:
put 'table name','row ','Column family:column name','new value'
put 'emp','1','professional data:salary','55'


